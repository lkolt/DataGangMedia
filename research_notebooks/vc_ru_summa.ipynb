{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from copy import deepcopy\n",
    "import gensim\n",
    "import pymorphy2\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir('data_test'):\n",
    "    with open('data_test/Соцсети1_новость.txt') as t:\n",
    "        text = t.readlines()\n",
    "        for i in range(len(text)):\n",
    "            text[i] = text[i].strip('\\n')\n",
    "        text = '.'.join(text)\n",
    "        text = re.sub(r'\\.+', \".\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_ft = gensim.models.fasttext.load_facebook_model('ru.bin', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_rus(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub('[^А-Яа-яA-Za-z]+', ' ', sentence).strip()\n",
    "    return sentence\n",
    "\n",
    "def mean_sent_vector(sentence_tokens):\n",
    "    return np.array([np.mean([pretrained_ft[w] for w in sentence_tokens if w in pretrained_ft]\n",
    "                     or [np.zeros(300)], axis=0)])\n",
    "\n",
    "\n",
    "sents = [sent.split('.') for sent in sent_tokenize(text)]\n",
    "sents = [item for sublist in sents for item in sublist if len(item) >= 30\n",
    "                                                        and '?' not in item]\n",
    "sents_storage = deepcopy(sents)\n",
    "n_sents = int(round(np.sqrt(len(sents_storage))))\n",
    "\n",
    "for i in range(len(sents)):\n",
    "    sents[i] = preprocessing_rus(sents[i])\n",
    "    sents[i] = word_tokenize(sents[i])\n",
    "    for j in range(len(sents[i])):\n",
    "        sents[i][j] = pymorphy2.MorphAnalyzer().parse(sents[i][j])[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user007/Documents/Workspace/venv/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  import sys\n",
      "/Users/user007/Documents/Workspace/venv/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "sent_vectors = []\n",
    "for sent in sents:\n",
    "    sent_vectors.append(np.squeeze(mean_sent_vector(sent)))\n",
    "sent_vectors = np.asarray(sent_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=n_sents).fit(sent_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=2, random_state=0)\n",
    "# reduced_features = pca.fit_transform(sent_vectors)\n",
    "\n",
    "# # reduce the cluster centers to 2D\n",
    "# reduced_cluster_centers = pca.transform(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,5))\n",
    "# plt.scatter(reduced_features[:,0], reduced_features[:,1], c=kmeans.predict(sent_vectors))\n",
    "# plt.scatter(reduced_cluster_centers[:, 0], reduced_cluster_centers[:,1], marker='x', s=150, c='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "centre_sents_idx = []\n",
    "for j in range(n_sents):\n",
    "    idx_cand = np.where(kmeans.labels_ == j)\n",
    "    vec_cand = sent_vectors[idx_cand]\n",
    "    closest, dist = pairwise_distances_argmin_min([kmeans.cluster_centers_[j]], vec_cand)\n",
    "    centre_sents_idx.append(idx_cand[0][int(closest)])\n",
    "centre_sents_idx = sorted(centre_sents_idx)\n",
    "summary = '. '.join([sents_storage[i] for i in centre_sents_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facebook стала отключать счётчики лайков пользователям в Австралии . Сейчас Facebook собирает отзывы пользователей, от них будет зависеть запуск функции в других странах, пояснил представитель соцсети. С апреля 2019 года компания тестирует функцию скрытия количества лайков под публикациями в Instagram, в зону тестирования включены пользователи семи стран\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
