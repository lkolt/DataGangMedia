{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pymorphy2\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_publication(path):\n",
    "    with open(path, 'r') as f:\n",
    "        data = eval(f.readlines()[0])\n",
    "        data = {'raw_text': data['title'] + \\\n",
    "                            data['intro'] + \\\n",
    "                            blocks2txt(data['blocks']),\n",
    "                   'genre': data['subsite']['name']}\n",
    "    return data\n",
    "\n",
    "\n",
    "def blocks2txt(blocks: list):\n",
    "    txt_pieces = []\n",
    "    for block in blocks:\n",
    "        if 'text' not in block['data']:\n",
    "            continue\n",
    "        txt_pieces.append(block['data']['text'])\n",
    "    return ' '.join(txt_pieces)\n",
    "\n",
    "\n",
    "m = pymorphy2.MorphAnalyzer()\n",
    "def preprocessing_rus(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^А-Яа-яA-Za-z]+', ' ', text).strip()\n",
    "    text = word_tokenize(text)\n",
    "    text = [m.parse(w)[0].normal_form for w in text if w not in stopwords.words('russian')]\n",
    "    return ' '.join(text)\n",
    "\n",
    "def label_changer(label):\n",
    "    label_map = {'Офис':    'Карьера',\n",
    "                 'Истории': 'Личный опыт',\n",
    "                 'vc.ru':   'Офтоп',\n",
    "                 'Промо':   'Маркетинг',\n",
    "                 'Будущее': 'Техника',\n",
    "                 'SEO':     'Финансы',\n",
    "                 'Торговля': 'Финансы',\n",
    "                 'Транспорт': 'Техника',\n",
    "                 'Офлайн':  'Офтоп',\n",
    "                 'Еда':     'Офтоп',\n",
    "                 'Медиа':   'Офтоп',\n",
    "                 'Соцсети': 'Сервисы',\n",
    "                 'Дизайн': 'Офтоп'}\n",
    "    \n",
    "    if label in label_map:\n",
    "        return label_map[label]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "path_to_data = 'db/'\n",
    "for fname in os.listdir(path_to_data):\n",
    "    if '.txt' in fname:\n",
    "        all_data.append(parse_publication(path_to_data+fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_data).drop_duplicates()\n",
    "df = df[df['genre'] != 'DataGang']\n",
    "df['genre'] = df['genre'].apply(label_changer)\n",
    "for bad_gen in 'Трибуна', 'Приёмная', 'Вопросы':\n",
    "    id_drop = df[df['genre'] == bad_gen].index\n",
    "    df = df.drop(id_drop)\n",
    "\n",
    "df['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Маркетинг      262\n",
       "Офтоп          181\n",
       "Финансы        173\n",
       "Сервисы        126\n",
       "Техника         88\n",
       "Карьера         80\n",
       "Личный опыт     68\n",
       "Право           49\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted = []\n",
    "for i, data in df.iterrows():\n",
    "    for j in textwrap.wrap(data['raw_text'], 3000):\n",
    "        splitted.append([j, data['genre']])\n",
    "\n",
    "df = pd.DataFrame(splitted)\n",
    "df.columns = ['raw_text', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Маркетинг      677\n",
       "Офтоп          408\n",
       "Финансы        408\n",
       "Сервисы        250\n",
       "Личный опыт    250\n",
       "Карьера        206\n",
       "Техника        177\n",
       "Право           77\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2453/2453 [05:36<00:00,  6.11it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.tqdm.pandas()\n",
    "\n",
    "df['raw_text'] = df['raw_text'].progress_apply(preprocessing_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>создание система контроль сдача отчётность бух...</td>\n",
       "      <td>Финансы</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>вести руководитель отдел именно проходить весь...</td>\n",
       "      <td>Финансы</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>аналитика который основать дать чек лист собст...</td>\n",
       "      <td>Финансы</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google запустить подписка приложение игра andr...</td>\n",
       "      <td>Сервисы</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>эффективный воронка продажа построить воронка ...</td>\n",
       "      <td>Маркетинг</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text      label\n",
       "0  создание система контроль сдача отчётность бух...    Финансы\n",
       "1  вести руководитель отдел именно проходить весь...    Финансы\n",
       "2  аналитика который основать дать чек лист собст...    Финансы\n",
       "3  google запустить подписка приложение игра andr...    Сервисы\n",
       "4  эффективный воронка продажа построить воронка ...  Маркетинг"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsvd_svc = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('svd', TruncatedSVD(n_components=1000)),\n",
    "                     ('svc', LinearSVC(C=0.15, class_weight='balanced'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='...\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('svd',\n",
       "                 TruncatedSVD(algorithm='randomized', n_components=1000,\n",
       "                              n_iter=5, random_state=None, tol=0.0)),\n",
       "                ('svc',\n",
       "                 LinearSVC(C=0.15, class_weight='balanced', dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsvd_svc.fit(df['raw_text'], df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_scores_baseline = cross_val_score(LinearSVC(C=0.2, class_weight='balanced'), X, y, cv=10, scoring='f1_micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5951417 , 0.53846154, 0.60323887, 0.62348178, 0.63967611,\n",
       "       0.5951417 , 0.65853659, 0.64609053, 0.6473029 , 0.61410788])"
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tsvd_svc, open('classification_pipeline.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.txt') as t:\n",
    "    test = t.readlines()\n",
    "    for sent in range(len(test)):\n",
    "        test[sent] = test[sent].strip('\\n')\n",
    "    test = '.'.join(test)\n",
    "    test = re.sub(r'\\.+', \".\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Право'"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsvd_svc.predict([test])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
